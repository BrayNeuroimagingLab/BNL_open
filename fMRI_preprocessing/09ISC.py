
"""
This program computes ISC values based on a parcellation

This program takes as an input time course data per parcel (in csv format) and temporal masks

Inputs into this program are generated from 06fittoparcellation
Temporal masks generated by 04advfuncpreprocessing


Made by Kirk Graff
kirk.graff@ucalgary.ca

Please email me if you have any questions :)
I'm not the best programmer so apologies if something is coded oddly!



"""



#what directory are your images saved in?
dir_start = '/Users/example/example/directory_with_all_MRI_scans_in_BIDS_format/'

#what network does each parcel belong to?
hierarchyfile = '/Users/example/example/Release/Hierarchy/MIST_PARCEL_ORDER.csv'

#what is the name of the file that lists a scan's avg motion?
avgmotionname = 'task-movie_boldMcf.nii.gz_rel_mean.rms'

#df with ages of each participant at time of scan
agedf = '/Users/example/example/agedf.csv'

#where do you want to save outputs?
outputfolder = '/Users/example/example/iscoutputs/'
summaryfolder = '/Users/example/example/pipelinesummary/'


#regression sub folders, arranged as list. Where all the outputs are saved, one for each pipeline
#first item in each pair is the folder, second item is the name of the image in each folder
regfolders = [    
            ['BandpassCensorGSR/','YCDetFltRgwchvRemArBetPar325'],
            ]

#which participants, and which image sessions per each participant
participants = [1,2,3,4,5,6]
imagesession = ["ses-0","ses-12"]


steps = ['isc','isclowhigh','summary']

#name of the temporal mask for each scan
tmaskname = 'MASK_TEMPORAL'

#if replacer is false, the program won't run if output image already exists
#if replacer is true, the program will write over outputs that already exist
replacer = False


numparcels = 325



"""*****************************************"""
"""ANYTHING BELOW HERE DOESN'T NEED CHANGING"""
"""**********(OR SO KIRK HOPES)*************"""
"""*****************************************"""
import pandas as pd
from scipy.stats.stats import pearsonr
import os 
import numpy as np
import time


totaltimer = time.time()

participant_folders = os.listdir(dir_start)
ages = pd.read_csv(agedf,index_col=0)
hdf = pd.read_csv(hierarchyfile)

numpipes = len(regfolders)


parcelnetlist = []           
for num in range(numparcels):
    parcel = num+1
    x = hdf.loc[hdf['s'+str(numparcels)] == parcel]['s7'].iloc[0]
    parcelnetlist.append(x)   




index=[]
for parcel in list(range(1,numparcels+1)):
    index.append('parcel'+str(parcel))
avgdf = pd.DataFrame({'index':index})
avgdf = avgdf.set_index('index')
avgdf2 = avgdf.copy()
complist = []
pipelist = []


if os.path.isdir(outputfolder) == False:
    os.makedirs(outputfolder)

if os.path.isdir(summaryfolder) == False:
    os.makedirs(summaryfolder)


avgmotion = []
avgmotquart = []
for i in participants:
    person = participant_folders[i]
    for j in imagesession:                                
        avgmotionfile = dir_start + person + "/" + j + "/func/" + person + "_" + j + "_" + avgmotionname
        with open(avgmotionfile) as file:
            for line in file:
                avgmotion.append(float(line))  
mot25 = np.percentile(avgmotion,25)
mot50 = np.percentile(avgmotion,50)
mot75 = np.percentile(avgmotion,75)
for item in avgmotion:
    if item > mot75:
        avgmotquart.append(4)
    elif item > mot50:
        avgmotquart.append(3)
    elif item > mot25:
        avgmotquart.append(2)
    else:
        avgmotquart.append(1)
        



for k in steps:
           
                
    if k == 'isc':

        for pipeline in regfolders:
            people = []
            sessions = []
            agelist = []
            avgmotion = []
            agecomp = []
            avgmotioncomp = []
            regfolder=pipeline[0]
            imgtype=pipeline[1]
            
            savefile = outputfolder + 'isc_' + regfolder[:-1] + "_" + imgtype + ".csv"
            psavefile = outputfolder + 'pisc_' + regfolder[:-1] + "_" + imgtype + ".csv"

            doit = True
            if replacer == False:
                if os.path.isfile(savefile) == True:
                    x = "ISC did not run; file already exists for " + savefile
                    print(x)
                    doit = False
            if doit == True:

                
                #create a list of relevant scans and their sessions, along with agelist, motion list, etc
                for i in participants:
                    person = participant_folders[i]
                    for j in imagesession:
                        if j == 'ses-0':
                            compses = 'ses-12'
                        else:
                            compses = 'ses-0'
                        
                        dir_in = dir_start + person + "/" + j + "/func/"
                        tmaskfile = dir_in + regfolder + person + "_" + j + "_" + tmaskname
                        parcelcsv = dir_in + regfolder + imgtype + "/" + person + "_" + j + "_" + imgtype + ".csv"
                        avgmotionfile = dir_start + person + "/" + j + "/func/" + person + "_" + j + "_" + avgmotionname
                        avgmotionfilecomp = dir_start + person + "/" + compses + "/func/" + person + "_" + compses + "_" + avgmotionname
                        if os.path.isfile(parcelcsv):
                            if os.path.isfile(tmaskfile):
                                age = float(ages.loc[ages['scan'] == person + "_" + j]['age'])
                                agelist.append(age)
                                
                                with open(avgmotionfile) as file:
                                    for line in file:
                                        avgmotion.append(float(line))
                                
                                people.append(person)
                                sessions.append(j)
                                
                                age = float(ages.loc[ages['scan'] == person + "_" + compses]['age'])
                                agecomp.append(age)
                                
                                with open(avgmotionfilecomp) as file:
                                    for line in file:
                                        avgmotioncomp.append(float(line))
                                
                        
    
                #create list of scan info. For each scan the ID# + session    
                scaninfo = []
                for val in range(len(people)):
                    theid = people[val][-3:]
                    ses = sessions[val]
                    if ses == 'ses-0':
                        theid = theid + '-00'
                    else:
                        theid = theid + '-12'
                    scaninfo.append(theid)
                
                scans = list(range(len(people)))
            
                #list of 450 zeros, for a temporal mask with 450 data points
                alltime = list(range(450))
                
                #DF of each person's temporal mask
                tmaskdf = pd.DataFrame({'time':alltime})
                
                for scan in scans:
                    person = people[scan]
                    j = sessions[scan]
                    dir_in = dir_start + person + "/" + j + "/func/"
                    tmaskfile = dir_in + regfolder + person + "_" + j + "_" + tmaskname
                    
                    tmask = []
                    currentline = 0
                    with open(tmaskfile) as file:
                        for line in file:
                            tmask.append(int(line))
                            
                    #if someone's temporal mask is less than 450, zeros will be added on
                    while len(tmask) < len(alltime):
                        tmask.append(0)
                    
                    #add this new row to the df of all temporal masks
                    tempdf = pd.DataFrame({'scan'+str(scan):tmask})
                    tmaskdf = tmaskdf.join(tempdf)
                
                del tmaskdf['time']
                
                #list of all possible comparisons
                fulllist = list(range(0,len(scans)*len(scans)))
                
                #edge lists, as they're arranged in the links dataframe generated below
                scan1list = []
                scan2list = []
                for num in range(len(scans)):
                    scan1column = [num]*len(scans)
                    scan1list.extend(scan1column)
                    scan2list.append(num)
       
                scan2list = scan2list*len(scans)
                
                
                comparisons = []
                comparisonswid = []
                tmasklist = []
                
                #create a list of all possible shared temporal masks. So for each comparison, what's the combined temporal mask?
                #also create a list of all the comparisons, with just raw numbers and with IDs
                print("Now creating shared temporal mask data")
                for scan in range(len(fulllist)):
                    scan1 = scan1list[scan]
                    scan2 = scan2list[scan]
                    if scan1 < scan2:
                        combined = tmaskdf['scan'+str(scan1)]*tmaskdf['scan'+str(scan2)]
                        tp1 = sum(tmaskdf['scan'+str(scan1)])
                        tp2 = sum(tmaskdf['scan'+str(scan2)])
                        tmasklist.append(list(combined))
                        
                        comparison = str(scan1)+'v'+str(scan2)
                        comparisonwid = scaninfo[scan1]+'v'+scaninfo[scan2]
                        tempdf = pd.DataFrame({comparison:combined})
                        
                        comparisons.append(comparison)
                        comparisonswid.append(comparisonwid)
                
                #this will be a list of list of lists
                # len(newparcellists) = the number of scans
                # len(newparcellists[0]) = 450 (one for each temporal point)
                # len(newparcellists[0][0]) = the number of parcels
                newparcellists = []
                
                #since the saved parcel data has removed censored data, this adds censored data back in as a row of x's for all parcels
                print("Now creating data frame of all parcel data for all people")
                for scan in scans:
                    person = people[scan]
                    j = sessions[scan]
                    dir_in = dir_start + person + "/" + j + "/func/"
            
                    parceldatacsv = dir_in + regfolder + imgtype + "/" + person + "_" + j + "_" + imgtype + ".csv"
                    parceldata = pd.read_csv(parceldatacsv, index_col=0)
                    parcellist = parceldata.values.tolist()
                    tmask = list(tmaskdf['scan'+str(scan)])
                    
                    currentplist = 0
                    newparcellist = []
                    for item in tmask:
                        if item == 0:
                            xlist = list('x'*numparcels)
                            newparcellist.append(xlist)
                        if item == 1:
                            newparcellist.append(parcellist[currentplist])
                            currentplist = currentplist + 1
                    
                    newparcellists.append(newparcellist)
                
                
                #timepoints shared
                tps = []
            
                #create a list of parcel names
                index = []
                for parcel in list(range(1,numparcels+1)):
                    index.append('parcel'+str(parcel))
                
                iscdf = pd.DataFrame({'index':index,'network':parcelnetlist})
                piscdf = iscdf.copy()
                
                #loop through all comparisons 1v2, 1v3, 1v4, etc
                for comparison in comparisons:
                    compnum = comparisons.index(comparison)
                    print("Now comparing " + comparison + " (" + str(compnum+1) + " of " + str(len(comparisons)) + ")")
                    
                    #how many shared timepoints are in the comparison between scan 1 and scan2?
                    timepoints = sum(tmasklist[compnum])
                    tps.append(timepoints)
                    scansincomp = comparison.split('v')
                    scan1 = int(scansincomp[0])
                    scan2 = int(scansincomp[1])
                    parceldata1 = newparcellists[scan1]
                    parceldata1 = list(map(list, zip(*parceldata1)))
                    parceldata2 = newparcellists[scan2]
                    parceldata2 = list(map(list, zip(*parceldata2)))
                    
                    #correlation for every parcel
                    thiscomp = []
                    
                    #figure out correlation for each parcel within this comparison
                    for parcel in list(range(numparcels)):
                        
                        #go through every row, and only include the rows that the combined temporal mask says are okay
                        scan1p = []
                        scan2p = []
                        
                        for tmaskrow in range(450):
                            if tmasklist[compnum][tmaskrow] == 1:
                                scan1p.append(parceldata1[parcel][tmaskrow])
                                scan2p.append(parceldata2[parcel][tmaskrow])                    
                            
                        #correlation between person 1 and person 2 for this parcel  
                        correl = pearsonr(scan1p,scan2p)
                        thiscomp.append(correl[0])
                        
                    #add these comparisons to the iscdf
                    tempdf = pd.DataFrame({comparison:thiscomp})
                    iscdf = iscdf.join(tempdf)
                
                #get average timepoints shared
                #tpsavg = sum(tps)/len(tps)
                #tpsindf = [np.nan] + tps + [tpsavg]
                
                #calculate average, and a vector version of the average
                zerocol = numparcels*[0]
                iscdf['avg'] = zerocol
                iscdf['vector'] = zerocol
                
                for comparison in comparisons:                    
                    iscdf[comparison] = np.arctanh(iscdf[comparison])
                    
                    iscdf['avg'] = iscdf[comparison] + iscdf['avg']
                    iscdf['vector'] = [qw**2 for qw in iscdf[comparison]] + iscdf['vector']
                
                iscdf['avg'] = iscdf['avg']/len(comparisons)
                iscdf['vector'] = [qw**0.5 for qw in iscdf['vector']]
                
                iscdf.to_csv(savefile,index=False)
    
                                          
                print("Now creating individual people df")
                peoplemean = []
                for scan in scans:
                    thisscaninfo = scaninfo[scan]
                    #figure out which comparisons are relevant for this scan
                    compsforscan = []
                    for comparison in comparisons:
                        scansincomp = comparison.split('v')
                        if str(scan) in scansincomp:
                            compsforscan.append(comparison)
        
                    
                    #df of just this scan's comparisons
                    newdf = iscdf[compsforscan]
                    personmean = newdf.mean(axis=1)
                    
                    tempdf = pd.DataFrame({thisscaninfo:personmean})
                    piscdf = piscdf.join(tempdf)
                
                
                
                piscdf = piscdf.set_index('index')
                
                #get average and a vector version of the average
                zerocol = numparcels*[0]
                piscdf['avg'] = zerocol
                piscdf['vector'] = zerocol
                
                for scan in scans:
                    piscdf['avg'] = piscdf[scaninfo[scan]] + piscdf['avg']
                    piscdf['vector'] = [qw**2 for qw in piscdf[scaninfo[scan]]] + piscdf['vector']
                
                piscdf['avg'] = piscdf['avg']/len(scans)
                piscdf['vector'] = [qw**0.5 for qw in piscdf['vector']]
                
                piscdf.to_csv(psavefile)
                    

    if k == 'isclowhigh':
        #this creates ISC information for low motion scans and high motion scans
        
        for pipeline in regfolders:        
            regfolder=pipeline[0]
            imgtype=pipeline[1]        
            openfile = outputfolder + 'isc_' + regfolder[:-1] + "_" + imgtype + ".csv"
            
            psavefilelvl = outputfolder + 'pisc_lvl_' + regfolder[:-1] + "_" + imgtype + ".csv"
            psavefilehvh = outputfolder + 'pisc_hvh_' + regfolder[:-1] + "_" + imgtype + ".csv"
            psavefilelvh = outputfolder + 'pisc_lvh_' + regfolder[:-1] + "_" + imgtype + ".csv"
            
            iscdf = pd.read_csv(openfile)   

            people = []
            sessions = []
            for i in participants:
                person = participant_folders[i]
                for j in imagesession:
                    if j == 'ses-0':
                        compses = 'ses-12'
                    else:
                        compses = 'ses-0'
                            
                    people.append(person)
                    sessions.append(j)
 
            scaninfo = []
            for val in range(len(people)):
                theid = people[val][-3:]
                ses = sessions[val]
                if ses == 'ses-0':
                    theid = theid + '-00'
                else:
                    theid = theid + '-12'
                scaninfo.append(theid)
            
            scans = list(range(len(people)))
            
            comparisons = []
            comparisonswid = []
                    
            fulllist = list(range(0,len(scans)*len(scans)))
            
            scan1list = []
            scan2list = []
            for num in range(len(scans)):
                scan1column = [num]*len(scans)
                scan1list.extend(scan1column)
                scan2list.append(num)
   
            scan2list = scan2list*len(scans)
            
            
            for scan in range(len(fulllist)):
                scan1 = scan1list[scan]
                scan2 = scan2list[scan]
                if scan1 < scan2:                    
                    comparison = str(scan1)+'v'+str(scan2)
                    comparisonwid = scaninfo[scan1]+'v'+scaninfo[scan2]
                    tempdf = pd.DataFrame({comparison:combined})
                    
                    comparisons.append(comparison)
                    comparisonswid.append(comparisonwid)           
            
            
            
            
            
            headsbelowmed = []
            headsabovemed = []
            for num in range(len(scaninfo)):
                if avgmotquart[num] < 3:
                    headsbelowmed.append(num)
            for num in range(len(scaninfo)):
                if avgmotquart[num] > 2:
                    headsabovemed.append(num)
                    
            #create list of low v low comparisons
            #create list of high v high comparisons
            #create list of low v high comparisons
            comparisonslvl = []
            comparisonshvh = []
            comparisonslvh = []
            
            for comparison in comparisons:
                scansincomp = comparison.split('v')
                scansincomp[0] = int(scansincomp[0])
                scansincomp[1] = int(scansincomp[1])
                
                if scansincomp[0] in headsbelowmed:
                    if scansincomp[1] in headsbelowmed:
                        comparisonslvl.append(comparison)
                    else:
                        comparisonslvh.append(comparison)
                        
                if scansincomp[0] in headsabovemed:
                    if scansincomp[1] in headsabovemed:
                        comparisonshvh.append(comparison)
                    else:
                        comparisonslvh.append(comparison)                
                
                
            piscdflvl = pd.DataFrame({'index':index,'network':parcelnetlist})
            #low v low
            print("low v low")
            for scan in headsbelowmed:
                thisscaninfo = scaninfo[scan]
                #figure out which comparisons are relevant for this scan
                compsforscan = []
                for comparison in comparisonslvl:
                    scansincomp = comparison.split('v')
                    if str(scan) in scansincomp:
                        compsforscan.append(comparison)            
            
                newdf = iscdf[compsforscan]
                #print("For " + str(scan) + ", the # of comparisons is " + str(len(newdf.columns)))
                personmean = newdf.mean(axis=1)
                
                tempdf = pd.DataFrame({thisscaninfo:personmean})
                piscdflvl = piscdflvl.join(tempdf)  
            
            piscdflvl = piscdflvl.set_index('index')
            
            #get average and a vector version of the average
            zerocol = numparcels*[0]
            piscdflvl['avg'] = zerocol
            #piscdf['vector'] = zerocol
            
            for scan in headsbelowmed:
                piscdflvl['avg'] = piscdflvl[scaninfo[scan]] + piscdflvl['avg']
                #piscdf['vector'] = [qw**2 for qw in piscdf[scaninfo[scan]]] + piscdf['vector']
            
            piscdflvl['avg'] = piscdflvl['avg']/len(headsbelowmed)
            #piscdf['vector'] = [qw**0.5 for qw in piscdf['vector']]
            #print("For lvl the # of columns in df is " + str(len(piscdflvl.columns)))
            
            piscdflvl.to_csv(psavefilelvl)

            #########################

            piscdfhvh = pd.DataFrame({'index':index,'network':parcelnetlist})
            #high v high
            #print("")
            print("high v high")
            for scan in headsabovemed:
                thisscaninfo = scaninfo[scan]
                #figure out which comparisons are relevant for this scan
                compsforscan = []
                for comparison in comparisonshvh:
                    scansincomp = comparison.split('v')
                    if str(scan) in scansincomp:
                        compsforscan.append(comparison)            
            
                newdf = iscdf[compsforscan]
                #print("For " + str(scan) + ", the # of comparisons is " + str(len(newdf.columns)))
                personmean = newdf.mean(axis=1)
                
                tempdf = pd.DataFrame({thisscaninfo:personmean})
                piscdfhvh = piscdfhvh.join(tempdf)  
            
            piscdfhvh = piscdfhvh.set_index('index')
            
            #get average and a vector version of the average
            zerocol = numparcels*[0]
            piscdfhvh['avg'] = zerocol
            #piscdf['vector'] = zerocol
            
            for scan in headsabovemed:
                piscdfhvh['avg'] = piscdfhvh[scaninfo[scan]] + piscdfhvh['avg']
                #piscdf['vector'] = [qw**2 for qw in piscdf[scaninfo[scan]]] + piscdf['vector']
            
            piscdfhvh['avg'] = piscdfhvh['avg']/len(headsabovemed)
            #piscdf['vector'] = [qw**0.5 for qw in piscdf['vector']]
            #print("For hvh the # of columns in df is " + str(len(piscdfhvh.columns)))
            
            piscdfhvh.to_csv(psavefilehvh)

            ###########################
            
            piscdflvh = pd.DataFrame({'index':index,'network':parcelnetlist})
            #low v high
            #print("")
            print("low v high")
            for scan in scans:
                thisscaninfo = scaninfo[scan]
                #figure out which comparisons are relevant for this scan
                compsforscan = []
                for comparison in comparisonslvh:
                    scansincomp = comparison.split('v')
                    if str(scan) in scansincomp:
                        compsforscan.append(comparison)            
            
                newdf = iscdf[compsforscan]
                #print("For " + str(scan) + ", the # of comparisons is " + str(len(newdf.columns)))
                personmean = newdf.mean(axis=1)
                
                tempdf = pd.DataFrame({thisscaninfo:personmean})
                piscdflvh = piscdflvh.join(tempdf)  
            
            piscdflvh = piscdflvh.set_index('index')
            
            #get average and a vector version of the average
            zerocol = numparcels*[0]
            piscdflvh['avg'] = zerocol
            #piscdf['vector'] = zerocol
            
            for scan in scans:
                piscdflvh['avg'] = piscdflvh[scaninfo[scan]] + piscdflvh['avg']
                #piscdf['vector'] = [qw**2 for qw in piscdf[scaninfo[scan]]] + piscdf['vector']
            
            piscdflvh['avg'] = piscdflvh['avg']/len(scans)
            #piscdf['vector'] = [qw**0.5 for qw in piscdf['vector']]
            print("For hvh the # of columns in df is " + str(len(piscdflvh.columns)))
            
            piscdflvh.to_csv(psavefilelvh)




    if k == 'summary':
        #this prints a bunch of random summary information

        summarydfheader = ['cerebellum (42)','net1avg','net1best','net1second','net1third','net1fourth','net1fifth',
             'mesolimbic (38)','net2avg','net2best','net2second','net2third','net2fourth','net2fifth',
             'somatomotor (15)','net3avg','net3best','net3second','net3third','net3fourth','net3fifth',
             'visual (29)','net4avg','net4best','net4second','net4third','net4fourth','net4fifth',
             'default (55)','net5avg','net5best','net5second','net5third','net5fourth','net5fifth',
             'frontoparietal (81)','net6avg','net6best','net6second','net6third','net6fourth','net6fifth',
             'ventralattn (65)','net7avg','net7best','net7second','net7third','net7fourth','net7fifth',
             'allnetworks (325)','totalavg','totalSD'
             ]
        summarydf = pd.DataFrame({'index':summarydfheader})        
        iscparceldf = pd.DataFrame({'parcel':list(range(1,numparcels+1))})   
        
        for pipeline in regfolders:        
            regfolder=pipeline[0]
            imgtype=pipeline[1]        
            openfile = outputfolder + 'pisc_' + regfolder[:-1] + "_" + imgtype + ".csv"  
            openfilelvl = outputfolder + 'pisc_lvl_' + regfolder[:-1] + "_" + imgtype + ".csv"  
            openfilehvh = outputfolder + 'pisc_hvh_' + regfolder[:-1] + "_" + imgtype + ".csv"  
            openfilelvh = outputfolder + 'pisc_lvh_' + regfolder[:-1] + "_" + imgtype + ".csv"  
            
            
            piscdf = pd.read_csv(openfile)
            pisclow = pd.read_csv(openfilelvl)
            pischigh = pd.read_csv(openfilehvh)
            pisclvh = pd.read_csv(openfilelvh)
            
            pisclow = pisclow.set_index('index')
            pischigh = pischigh.set_index('index')
            pisclvh = pisclvh.set_index('index')
            
            
            tempdf = pd.DataFrame({regfolder:piscdf['avg']})
            iscparceldf = iscparceldf.join(tempdf)
            
            piscdf = piscdf.set_index('index')
            
            #get a subdf of just the low and high motion people
            pischead = list(piscdf.columns.values)
            pischead.remove('avg')
            pischead.remove('vector')
            pischead.remove('network')
        
            pipelinenetdata = []
            
            #cycle through all 7 networks
            for net in range(1,8):
                #create a subdf for just this network
                df = piscdf.loc[piscdf['network'] == net]
                #list the best connections for this network and get the top 5
                df_sort = df.sort_values(by=['avg'], ascending=False)
                df_best = df_sort.head(5)
                #get the best 5 connection strengths
                best5 = df_best['avg']
                best5str = [str(round(best,3)) for best in best5]
                
                #put in a nan into the list and the mean of the whole network
                pipelinenetdata.append(np.nan)
                netmean = sum(df['avg'])/len(df)
                pipelinenetdata.append(netmean)
                
                #get the name of the parcel and its value
                rank = df_best.index[0] + " " + best5str[0]
                pipelinenetdata.append(rank)
                rank = df_best.index[1] + " " + best5str[1]
                pipelinenetdata.append(rank)
                rank = df_best.index[2] + " " + best5str[2]
                pipelinenetdata.append(rank)
                rank = df_best.index[3] + " " + best5str[3]
                pipelinenetdata.append(rank)
                rank = df_best.index[4] + " " + best5str[4]
                pipelinenetdata.append(rank)        
        
            pipelinenetdata.append(np.nan)
            allmean = np.nanmean(piscdf['avg'])
            pipelinenetdata.append(allmean)
            allstd = np.nanstd(piscdf['avg'])
            pipelinenetdata.append(allstd)
            tempdf = pd.DataFrame({pipeline[0]:pipelinenetdata})
            summarydf = summarydf.join(tempdf)
            
            #create dataframe of the average from each parcel for all the different pipelines tested
            tempdf = pd.DataFrame({pipeline[0]:piscdf['avg']})
            tempdf2 = pd.DataFrame({pipeline[0]:piscdf['avg'],pipeline[0]+'low':pisclow['avg'],pipeline[0]+'high':pischigh['avg'],pipeline[0]+'lvh':pisclvh['avg']})
            complist.append(pipeline[0])
            complist.append(pipeline[0]+'low')
            complist.append(pipeline[0]+'high')
            complist.append(pipeline[0]+'lvh')
            pipelist.append(pipeline[0])
            avgdf = avgdf.join(tempdf)
            avgdf2 = avgdf2.join(tempdf2)
        
        
        
        summarydf = summarydf.set_index('index')
        print(summarydf.to_string())
        print("")
        summarydf.to_csv(outputfolder + 'isc_summary.csv')
        del iscparceldf['parcel']
        iscparceldf = np.arctanh(iscparceldf)
        comparisondf = iscparceldf.corr()
        print(comparisondf.to_string())
        print("")
        
        avglist = []
        for parnum in list(range(1,numparcels+1)):
            parcel = 'parcel' + str(parnum)
            paravg = sum(avgdf.loc[parcel])/len(avgdf.loc[parcel])
            avglist.append(paravg)
        tempdf = pd.DataFrame({'network':parcelnetlist,'avg':avglist})
        avgdf['network'] = parcelnetlist
        avgdf['avg'] = avglist
        avgdf_sort = avgdf.sort_values(by=['avg'], ascending=False)
        bestindexlist = list(avgdf_sort.head(15).index)
        bestindexlist = list(avgdf_sort.index)
        bestnetlist = list(avgdf_sort['network'])

        summaryrankdf = pd.DataFrame({'parcel':bestindexlist,'network':bestnetlist})
        summaryranknumdf = summaryrankdf.copy()

        summaryrankdf2 = summaryrankdf.copy()
        summaryranknumdf2 = summaryrankdf.copy()
        
        wb = []
        top10 = []
        vis = []
        dmn = []
        fropor = []
        stdev = []
        
        wb2 = []
        top102 = []
        vis2 = []
        dmn2 = []
        fropor2 = []
        stdev2 = []
        
        for pipeline in regfolders:        
            regfolder=pipeline[0]
            imgtype=pipeline[1] 
            avgdf_pipesort = avgdf.sort_values(by=[regfolder],ascending=False)
            thispipeindexlist = list(avgdf_pipesort.index)
            piperanks = []
            piperanksnum = []
            for parcel in bestindexlist:
                rank = thispipeindexlist.index(parcel) + 1
                valu = avgdf[regfolder].loc[parcel]
                combin = str(round(valu,3)) + " (" + str(rank) + ")"
                #piperanks.append(rank)
                piperanks.append(combin)
                piperanksnum.append(valu)
            summaryrankdf[regfolder] = piperanks
            summaryranknumdf[regfolder] = piperanksnum
        print(summaryrankdf.head(15).to_string())
        
        for pipeline in regfolders:
            regfolder=pipeline[0]
            wb.append(sum(summaryranknumdf[regfolder])/len(summaryranknumdf[regfolder]))
            stdev.append(np.std(summaryranknumdf[regfolder]))
            top10.append(sum(summaryranknumdf.head(10)[regfolder])/len(summaryranknumdf.head(10)[regfolder]))
            subdf = summaryranknumdf.loc[summaryranknumdf['network'] == 4]
            vis.append(sum(subdf[regfolder])/len(subdf[regfolder]))
            subdf = summaryranknumdf.loc[summaryranknumdf['network'] == 5]
            dmn.append(sum(subdf[regfolder])/len(subdf[regfolder]))            
            subdf = summaryranknumdf.loc[summaryranknumdf['network'] == 6]
            fropor.append(sum(subdf[regfolder])/len(subdf[regfolder]))    

        summaryfile1 = summaryfolder + 'iscsummary1.csv'
        summarysavedf = pd.DataFrame({'pipeline':pipelist,'mean whole':wb,'sd':stdev,'mean 10 best':top10,'mean visual':vis,'mean DMN':dmn,'mean fropar':fropor})
        summarysavedf = summarysavedf.sort_values(by='pipeline')
        summarysavedf = summarysavedf.reset_index(drop=True)
        summarysavedf.to_csv(summaryfile1)
        
        
        for regfolder in complist:        
            avgdf2_pipesort = avgdf2.sort_values(by=[regfolder],ascending=False)
            thispipeindexlist = list(avgdf2_pipesort.index)
            piperanks = []
            piperanksnum = []
            for parcel in bestindexlist:
                rank = thispipeindexlist.index(parcel) + 1
                valu = avgdf2[regfolder].loc[parcel]
                combin = str(round(valu,3)) + " (" + str(rank) + ")"
                #piperanks.append(rank)
                piperanks.append(combin)
                piperanksnum.append(valu)
            summaryrankdf2[regfolder] = piperanks
            summaryranknumdf2[regfolder] = piperanksnum
        print(summaryrankdf2.head(15).to_string())        
            
        for regfolder in complist:
            wb2.append(sum(summaryranknumdf2[regfolder])/len(summaryranknumdf2[regfolder]))
            stdev2.append(np.std(summaryranknumdf2[regfolder]))
            top102.append(sum(summaryranknumdf2.head(10)[regfolder])/len(summaryranknumdf2.head(10)[regfolder]))
            subdf = summaryranknumdf2.loc[summaryranknumdf2['network'] == 4]
            vis2.append(sum(subdf[regfolder])/len(subdf[regfolder]))                
            subdf = summaryranknumdf2.loc[summaryranknumdf['network'] == 5]
            dmn2.append(sum(subdf[regfolder])/len(subdf[regfolder]))            
            subdf = summaryranknumdf2.loc[summaryranknumdf['network'] == 6]
            fropor2.append(sum(subdf[regfolder])/len(subdf[regfolder]))  

        summaryfile2 = summaryfolder + 'iscsummary2.csv'
        summarysavedf2 = pd.DataFrame({'pipeline':complist,'mean whole':wb2,'sd':stdev2,'mean 10 best':top102,'mean visual':vis2,'mean DMN':dmn2,'mean fropar':fropor2})
        summarysavedf2 = summarysavedf2.sort_values(by='pipeline')
        summarysavedf2 = summarysavedf2.reset_index(drop=True)
        summarysavedf2.to_csv(summaryfile2)
            
        


 
      



print("")

totaltimer = round(time.time()-totaltimer,3)
totaltimermin = round(totaltimer/60,3)
x = "All steps took " + str(totaltimer) + " s to run."
print(x)
x = "(which is " + str(totaltimermin) + " minutes)"
print(x)



